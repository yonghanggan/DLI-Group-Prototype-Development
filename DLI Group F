from google.colab import drive
drive.mount('/content/drive')


!unzip "/content/drive/MyDrive/CICIDS2017_Data/MachineLearningCSV.zip" -d "/content/cicids2017"


import os

folder_path = "/content/cicids2017/MachineLearningCVE"
for file in os.listdir(folder_path):
    print(file)


import pandas as pd

# Use the correct full path and exact filename
df = pd.read_csv('/content/cicids2017/MachineLearningCVE/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv')

# Show dataset shape and first few rows
print("Shape:", df.shape)
df.head()


# List all columns and their data types
df.info()


import pandas as pd
from sklearn.preprocessing import StandardScaler

# 1. Strip extra spaces from column names
df.columns = df.columns.str.strip()

# 2. Convert all numeric fields (already done via pandas)
# (no need to drop extra columns)

# 3. Handle missing values (drop rows with NaN or Inf)
df = df.replace([float('inf'), float('-inf')], pd.NA)
df = df.dropna()

# 4. Encode 'Label' column: BENIGN = 0, attack = 1
df['Label'] = df['Label'].apply(lambda x: 0 if x == 'BENIGN' else 1)

# 5. Split features and labels
X = df.drop('Label', axis=1)
y = df['Label']

# 6. Normalize the features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

print("âœ… Data cleaned and normalized.")


from sklearn.model_selection import train_test_split

# Split into training and testing sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42, stratify=y
)

print("Train size:", X_train.shape[0])
print("Test size:", X_test.shape[0])


# Import TensorFlow and necessary Keras components
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout


# Define a Sequential deep learning model
model = Sequential([
    # First hidden layer: 64 neurons, ReLU activation, input shape matches number of features
    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),

    # Dropout layer: randomly sets 30% of inputs to 0 during training to prevent overfitting
    Dropout(0.3),

    # Second hidden layer: 32 neurons, ReLU activation
    Dense(32, activation='relu'),

    # Another Dropout layer: drops 20% of inputs
    Dropout(0.2),

    # Output layer: 1 neuron, sigmoid activation for binary classification (benign vs attack)
    Dense(1, activation='sigmoid')
])

# Compile the model with optimizer, loss function, and performance metrics
model.compile(
    optimizer='adam',                     # Adaptive learning rate optimizer
    loss='binary_crossentropy',           # Suitable for binary classification tasks
    metrics=[
        'accuracy',                       # Overall accuracy
        tf.keras.metrics.Precision(),     # Precision: how many predicted attacks were correct
        tf.keras.metrics.Recall()         # Recall: how many actual attacks were caught
    ]
)

# Show model architecture summary
model.summary()


# Train the model using training data, validate on test data
history = model.fit(
    X_train, y_train,                     # Input features and labels for training
    validation_data=(X_test, y_test),     # Validation split (test set)
    epochs=10,                            # Number of full passes through the dataset
    batch_size=256,                       # Number of samples per training batch
    verbose=1                             # Show training progress
)


from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Predict on test set
y_pred_prob = model.predict(X_test)
y_pred = (y_pred_prob > 0.5).astype("int32")

# Generate confusion matrix
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Benign', 'Attack'])

# Plot it
disp.plot(cmap='Blues')


from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt

# Get false positive rate, true positive rate
fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)
roc_auc = auc(fpr, tpr)

# Plot ROC
plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (AUC = {:.4f})'.format(roc_auc))
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC)')
plt.legend(loc='lower right')
plt.grid()
plt.show()
